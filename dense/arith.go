// Code generated by genlib3. DO NOT EDIT

package dense

import (
	"gorgonia.org/tensor"
	"gorgonia.org/tensor/internal/errors"
)

// Add performs `t + u`.
func (t *Dense[DT]) Add(u *Dense[DT], opts ...FuncOpt) (*Dense[DT], error) {
	e, newAPT, newAPU, retVal, fo, err := tensor.PrepBinOpCis[DT, *Dense[DT]](t, u, opts...)
	if err != nil {
		return nil, err
	}
	ctx := fo.Ctx
	toIncr := fo.Incr
	toBroadcast := fo.Broadcast.BroadcastData()

	adder, ok := e.(tensor.Adder[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, adder, errors.ThisFn())
	}

	switch {
	case toBroadcast:
		err = adder.AddBroadcastable(ctx, t, u, retVal, newAPT, newAPU, toIncr)
	default:
		if err := checkCompatibleShape(t.Shape(), u.Shape())(); err != nil {
			return retVal, err
		}
		if err = adder.Add(ctx, t, u, retVal, toIncr); err != nil {
			return nil, err
		}
		err = postOpBroadcastReshape(fo.Broadcast, t, u, retVal)
	}
	return retVal, err
}

// AddScalar performs `t + s`. If `scalarOnLeft` is true, then it performs `s + t`.
func (t *Dense[DT]) AddScalar(s DT, scalarOnLeft bool, opts ...FuncOpt) (*Dense[DT], error) {
	e, retVal, fo, err := tensor.PrepBinOpScalarCis(t, s, opts...)
	if err != nil {
		return nil, err
	}
	ctx, toIncr := fo.Ctx, fo.Incr

	adder, ok := e.(tensor.Adder[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, adder, errors.ThisFn())
	}

	if err = adder.AddScalar(ctx, t, s, retVal, scalarOnLeft, toIncr); err != nil {
		return nil, err
	}
	return retVal, nil
}

// Sub performs `t - u`.
func (t *Dense[DT]) Sub(u *Dense[DT], opts ...FuncOpt) (*Dense[DT], error) {
	e, newAPT, newAPU, retVal, fo, err := tensor.PrepBinOpCis[DT, *Dense[DT]](t, u, opts...)
	if err != nil {
		return nil, err
	}
	ctx := fo.Ctx
	toIncr := fo.Incr
	toBroadcast := fo.Broadcast.BroadcastData()

	suber, ok := e.(tensor.BasicArither[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, suber, errors.ThisFn())
	}

	switch {
	case toBroadcast:
		err = suber.SubBroadcastable(ctx, t, u, retVal, newAPT, newAPU, toIncr)
	default:
		if err := checkCompatibleShape(t.Shape(), u.Shape())(); err != nil {
			return retVal, err
		}
		if err = suber.Sub(ctx, t, u, retVal, toIncr); err != nil {
			return nil, err
		}
		err = postOpBroadcastReshape(fo.Broadcast, t, u, retVal)
	}
	return retVal, err
}

// SubScalar performs `t - s`. If `scalarOnLeft` is true, then it performs `s - t`.
func (t *Dense[DT]) SubScalar(s DT, scalarOnLeft bool, opts ...FuncOpt) (*Dense[DT], error) {
	e, retVal, fo, err := tensor.PrepBinOpScalarCis(t, s, opts...)
	if err != nil {
		return nil, err
	}
	ctx, toIncr := fo.Ctx, fo.Incr

	suber, ok := e.(tensor.BasicArither[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, suber, errors.ThisFn())
	}

	if err = suber.SubScalar(ctx, t, s, retVal, scalarOnLeft, toIncr); err != nil {
		return nil, err
	}
	return retVal, nil
}

// Mul performs `t * u`.
func (t *Dense[DT]) Mul(u *Dense[DT], opts ...FuncOpt) (*Dense[DT], error) {
	e, newAPT, newAPU, retVal, fo, err := tensor.PrepBinOpCis[DT, *Dense[DT]](t, u, opts...)
	if err != nil {
		return nil, err
	}
	ctx := fo.Ctx
	toIncr := fo.Incr
	toBroadcast := fo.Broadcast.BroadcastData()

	muler, ok := e.(tensor.BasicArither[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, muler, errors.ThisFn())
	}

	switch {
	case toBroadcast:
		err = muler.MulBroadcastable(ctx, t, u, retVal, newAPT, newAPU, toIncr)
	default:
		if err := checkCompatibleShape(t.Shape(), u.Shape())(); err != nil {
			return retVal, err
		}
		if err = muler.Mul(ctx, t, u, retVal, toIncr); err != nil {
			return nil, err
		}
		err = postOpBroadcastReshape(fo.Broadcast, t, u, retVal)
	}
	return retVal, err
}

// MulScalar performs `t * s`. If `scalarOnLeft` is true, then it performs `s * t`.
func (t *Dense[DT]) MulScalar(s DT, scalarOnLeft bool, opts ...FuncOpt) (*Dense[DT], error) {
	e, retVal, fo, err := tensor.PrepBinOpScalarCis(t, s, opts...)
	if err != nil {
		return nil, err
	}
	ctx, toIncr := fo.Ctx, fo.Incr

	muler, ok := e.(tensor.BasicArither[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, muler, errors.ThisFn())
	}

	if err = muler.MulScalar(ctx, t, s, retVal, scalarOnLeft, toIncr); err != nil {
		return nil, err
	}
	return retVal, nil
}

// Div performs `t / u`.
func (t *Dense[DT]) Div(u *Dense[DT], opts ...FuncOpt) (*Dense[DT], error) {
	e, newAPT, newAPU, retVal, fo, err := tensor.PrepBinOpCis[DT, *Dense[DT]](t, u, opts...)
	if err != nil {
		return nil, err
	}
	ctx := fo.Ctx
	toIncr := fo.Incr
	toBroadcast := fo.Broadcast.BroadcastData()

	diver, ok := e.(tensor.BasicArither[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, diver, errors.ThisFn())
	}

	switch {
	case toBroadcast:
		err = diver.DivBroadcastable(ctx, t, u, retVal, newAPT, newAPU, toIncr)
	default:
		if err := checkCompatibleShape(t.Shape(), u.Shape())(); err != nil {
			return retVal, err
		}
		if err = diver.Div(ctx, t, u, retVal, toIncr); err != nil {
			return nil, err
		}
		err = postOpBroadcastReshape(fo.Broadcast, t, u, retVal)
	}
	return retVal, err
}

// DivScalar performs `t / s`. If `scalarOnLeft` is true, then it performs `s / t`.
func (t *Dense[DT]) DivScalar(s DT, scalarOnLeft bool, opts ...FuncOpt) (*Dense[DT], error) {
	e, retVal, fo, err := tensor.PrepBinOpScalarCis(t, s, opts...)
	if err != nil {
		return nil, err
	}
	ctx, toIncr := fo.Ctx, fo.Incr

	diver, ok := e.(tensor.BasicArither[DT, *Dense[DT]])
	if !ok {
		return nil, errors.Errorf(errors.EngineSupport, e, diver, errors.ThisFn())
	}

	if err = diver.DivScalar(ctx, t, s, retVal, scalarOnLeft, toIncr); err != nil {
		return nil, err
	}
	return retVal, nil
}
